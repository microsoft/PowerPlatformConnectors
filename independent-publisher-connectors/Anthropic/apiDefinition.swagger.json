swagger: '2.0'
info:
  title: Anthropic
  description: >-
    Claude is a large language model (LLM) built by Anthropic. It's trained to
    be a helpful assistant in a conversational tone.
  version: 1.1.0
  contact:
    name: Troy Taylor
    url: https://www.hitachisolutions.com
    email: ttaylor@hitachisolutions.com
host: api.anthropic.com
basePath: /
schemes:
  - https
consumes:
  - application/json
produces:
  - application/json
paths:
  /v1/complete:
    post:
      responses:
        '200':
          description: default
          schema:
            type: object
            properties:
              completion:
                type: string
                description: The completion.
                title: Completion
              stop:
                type: string
                description: The stop.
                title: Stop
              stop_reason:
                type: string
                description: The stop reason.
                title: Stop Reason
              truncated:
                type: boolean
                description: Whether truncated.
                title: Truncated
              log_id:
                type: string
                description: The log identifier.
                title: Log ID
              model:
                type: string
                description: The model.
                title: Model
              exception:
                type: string
                description: The exception.
                title: Exception
      summary: Create a text completion
      description: Send a prompt to Claude for completion.
      operationId: ClaudePost
      parameters:
        - name: body
          in: body
          required: false
          schema:
            type: object
            properties:
              prompt:
                type: string
                description: The prompt you want Claude to complete.
                title: Prompt
              model:
                type: string
                description: The version of Claude answering your request.
                title: Model
                default: claude-2.1
                enum:
                  - claude-2.1
                  - claude-2.0
                  - claude-instant-1.2
              max_tokens_to_sample:
                type: integer
                format: int32
                description: A maximum number of tokens to generate before stopping.
                title: Max Tokens To Sample
              stop_sequences:
                type: array
                items:
                  type: string
                description: >-
                  A list of strings upon which to stop generating. You probably
                  want ["


                  Human:"], as that's the cue for the next turn in the dialog
                  agent.
                title: Stop Sequences
              stream:
                type: boolean
                description: Whether to incrementally stream the response using SSE.
                title: Stream
              temperature:
                type: number
                format: float
                description: >-
                  Amount of randomness injected into the response. Ranges from 0
                  to 1. Use temp closer to 0 for analytical / multiple choice,
                  and temp closer to 1 for creative and generative tasks.
                title: Temperature
              top_k:
                type: integer
                format: int32
                description: Only sample from the top K options for each subsequent token.
                title: Top K
              top_p:
                type: number
                format: float
                description: >-
                  Does nucleus sampling, in which we compute the cumulative
                  distribution over all the options for each subsequent token in
                  decreasing probability order and cut it off once it reaches a
                  particular probability specified by top_p.
                title: Top P
            required:
              - prompt
              - max_tokens_to_sample
  /v1/messages:
    post:
      responses:
        '200':
          description: default
          schema:
            type: object
            properties:
              completion:
                type: string
                description: The completion.
                title: Completion
              id:
                type: string
                description: The identifier.
                title: ID
              model:
                type: string
                description: The model.
                title: Model
              stop_reason:
                type: string
                description: The stop reason.
                title: Stop Reason
              type:
                type: string
                description: The type.
                title: Type
      summary: Create a message
      description: Send a prompt to Claude for message.
      operationId: MessagePost
      parameters:
        - name: body
          in: body
          required: false
          schema:
            type: object
            properties:
              model:
                type: string
                description: The version of Claude answering your request.
                title: Model
                enum:
                  - claude-3-opus-20240229
                  - claude-3-sonnet-20240229
                  - claude-3-haiku-20240307
                  - claude-2.1
                  - claude-2.0
                  - claude-instant-1.2
                default: claude-3-opus-20240229
              messages:
                type: array
                items:
                  type: object
                  properties:
                    role:
                      type: string
                      description: The role.
                      title: Role
                    content:
                      type: string
                      description: The content.
                      title: Content
                  required:
                    - role
                    - content
                title: Messages
              max_tokens:
                type: integer
                format: int32
                description: A maximum number of tokens to generate before stopping.
                title: Max Tokens
              metadata:
                type: object
                properties: {}
                description: The metadata object.
                title: metadata
              stop_sequences:
                type: array
                items:
                  type: string
                description: >-
                  A list of strings upon which to stop generating. You probably
                  want ["


                  Human:"], as that's the cue for the next turn in the dialog
                  agent.
                title: Stop Sequences
              system:
                type: string
                description: The system.
                title: System
              temperature:
                type: number
                format: float
                description: >-
                  Amount of randomness injected into the response. Ranges from 0
                  to 1. Use temp closer to 0 for analytical / multiple choice,
                  and temp closer to 1 for creative and generative tasks.
                title: temperature
              tools:
                type: array
                items:
                  type: object
                  properties:
                    name:
                      type: string
                      description: The name.
                      title: Name
                    description:
                      type: string
                      description: The description.
                      title: Description
                    input_schema:
                      type: object
                      properties: {}
                      description: The input schema object.
                      title: Input Schema
                title: Tools
              top_k:
                type: integer
                format: int32
                description: Only sample from the top K options for each subsequent token.
                title: Top K
              top_p:
                type: number
                format: float
                description: >-
                  Does nucleus sampling, in which we compute the cumulative
                  distribution over all the options for each subsequent token in
                  decreasing probability order and cut it off once it reaches a
                  particular probability specified by top_p.
                title: Top P
            required:
              - max_tokens
              - messages
              - model
definitions: {}
parameters: {}
responses: {}
securityDefinitions:
  API Key:
    type: apiKey
    in: header
    name: X-API-Key
security:
  - API Key: []
tags: []
x-ms-connector-metadata:
  - propertyName: Website
    propertyValue: https://www.anthropic.com/
  - propertyName: Privacy policy
    propertyValue: https://console.anthropic.com/legal/privacy
  - propertyName: Categories
    propertyValue: AI
